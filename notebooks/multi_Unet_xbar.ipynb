{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "import itertools as iter\n",
    "from matplotlib import pyplot as plt\n",
    "import sys; sys.path.append('..')\n",
    "from experiments.functions_Filippo import *\n",
    "import warnings\n",
    "import itertools\n",
    "from IPython.display import Markdown\n",
    "import io\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0);\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import local modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.dirname(os.path.dirname(os.path.realpath('__file__')))\n",
    "sys.path.insert(0, os.path.join(root, 'src'))\n",
    "\n",
    "\n",
    "from dataset import dataset_dir\n",
    "from cs import generate_sensing_matrix\n",
    "from cs.utils import compute_rsnr\n",
    "from models.unet import UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardware settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = \"1\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpus\n",
    "\n",
    "os.environ['SCIPY_USE_PROPACK'] = \"True\"\n",
    "\n",
    "# limit number of parallel threads numpy spawns\n",
    "workers_mp = 1 # number of workers for mp.pool\n",
    "threads_np = \"1\" # number of threads np generates for every worker\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = threads_np\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = threads_np\n",
    "os.environ[\"MKL_NUM_THREADS\"] = threads_np\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = threads_np\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = threads_np\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_vars(pop=None, verbose=False):\n",
    "    _bundle = get_cell_vars_as_dict(ipy=get_ipython(), out=io.StringIO(), glob=globals(), offset=0)\n",
    "    \n",
    "    if pop is not None and pop in _bundle.keys():\n",
    "        _bundle.pop(pop)\n",
    "\n",
    "    for k, v in _bundle.items():\n",
    "        _b = _bundle.copy()\n",
    "        _b.pop(k)\n",
    "        if v==_b or v=={}:\n",
    "            _bundle.pop(k)\n",
    "            break;\n",
    "    \n",
    "    if verbose: [print(k) for k in _bundle]\n",
    "    return _bundle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Unet Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_param = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 10_000\n",
    "N = 2_000_000\n",
    "# N = 100_000\n",
    "n = 128\n",
    "# seed_ecg = 42\n",
    "seed_ecg = 11\n",
    "fs = 256 # sampling freq\n",
    "hr0 = 60 # heart rate low\n",
    "hr1 = 100 # hear rate high\n",
    "isnr = 35 # dB (intrinsic snr)\n",
    "\n",
    "_b = cell_vars(pop='_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_param = bundle_param | _b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 48\n",
    "mode_A = ['rakeness']\n",
    "seed_A = 0\n",
    "index_A = 0\n",
    "orth = True\n",
    "str_corr = '96af96a7ddfcb2f6059092c250e18f2a'\n",
    "N_try_A = 1_000\n",
    "loc = 0.25 # localization for rakeness\n",
    "\n",
    "_b = cell_vars(pop='_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_param = bundle_param | _b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unet parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 1\n",
    "# expanded_channels = [64, 32, 16]\n",
    "expanded_channels = [32]\n",
    "# step_number = [4, 3, 2]\n",
    "step_number = [3]\n",
    "# kernel_size = [3, 5, 7]\n",
    "kernel_size = [3]\n",
    "residual = True\n",
    "use_batch_norm = False\n",
    "simple_pool = False\n",
    "# seed_torch = 0\n",
    "seed_torch = [0, 1, 2, 3]\n",
    "# seed_torch = [0, 1, 2, 3]\n",
    "\n",
    "_b = cell_vars(pop='_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_param = bundle_param | _b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset for A generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ecg_N_forA = 10_000\n",
    "_n_forA = 128\n",
    "_fs_forA = 256\n",
    "_hr0_forA = 60\n",
    "_hr1_forA = 100\n",
    "_isnr_forA = 35\n",
    "_seed_forA = 0\n",
    "\n",
    "_b = cell_vars(pop='_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_param_A_dataset = _b.copy()\n",
    "bundle_param = bundle_param_A_dataset | bundle_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_ecg_N_forA': 10000,\n",
       " '_n_forA': 128,\n",
       " '_fs_forA': 256,\n",
       " '_hr0_forA': 60,\n",
       " '_hr1_forA': 100,\n",
       " '_isnr_forA': 35,\n",
       " '_seed_forA': 0,\n",
       " 'N': 2000000,\n",
       " 'n': 128,\n",
       " 'seed_ecg': 11,\n",
       " 'fs': 256,\n",
       " 'hr0': 60,\n",
       " 'hr1': 100,\n",
       " 'isnr': 35,\n",
       " 'm': 48,\n",
       " 'mode_A': ['rakeness'],\n",
       " 'seed_A': 0,\n",
       " 'index_A': 0,\n",
       " 'orth': True,\n",
       " 'str_corr': '96af96a7ddfcb2f6059092c250e18f2a',\n",
       " 'N_try_A': 1000,\n",
       " 'loc': 0.25,\n",
       " 'in_channels': 1,\n",
       " 'expanded_channels': [32],\n",
       " 'step_number': [3],\n",
       " 'kernel_size': [3],\n",
       " 'residual': True,\n",
       " 'use_batch_norm': False,\n",
       " 'simple_pool': False,\n",
       " 'seed_torch': [0, 1, 2, 3]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bundle_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "cuda_index = torch.cuda.device_count() - 1\n",
    "device = torch.device(f\"cuda:{cuda_index}\" if use_cuda else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MODELS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOTAL  number of models: 4\n",
      "\n",
      "LOADED number of models: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "verbose_load  = False\n",
    "bundle_all, param_unique_list = unravel_bundle_param(bundle_param)\n",
    "print('LOADING MODELS:')\n",
    "model_list = np.array([from_bundle_to_model(b, device, verbose=False) for b in tqdm(bundle_all)])\n",
    "\n",
    "ind_loaded = model_list!=None\n",
    "\n",
    "print()\n",
    "print(f\"TOTAL  number of models: {len(model_list)}\\n\")\n",
    "print(f\"LOADED number of models: {len(model_list[ind_loaded])}\\n\")\n",
    "\n",
    "if verbose_load:\n",
    "    for _m, _p in zip(model_list, param_unique_list):\n",
    "        if _m is not None:\n",
    "            display(Markdown(color('LOADED:  ', '', _p, code=\"00ffff\")));\n",
    "        else:\n",
    "            display(Markdown(color('MISSING: ', '', _p)));\n",
    "\n",
    "model_list, param_unique_list = model_list[ind_loaded], np.array(param_unique_list)[ind_loaded]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract ECG (dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ecg = from_bundle_to_ecg_path(bundle_param)\n",
    "\n",
    "with open(path_ecg, 'rb') as f:\n",
    "    ecg = pkl.load(f)[:, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract A (sensing matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sensing matrix rakeness (rsnr: 27.64dB (with bpdn) -- seed: 30808)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dict_A = {}\n",
    "l_mode_A = bundle_param['mode_A']\n",
    "if type(l_mode_A) is not list:\n",
    "    l_mode_A = [l_mode_A]\n",
    "\n",
    "\n",
    "for _mode_A in l_mode_A:\n",
    "\n",
    "    _bundle_param = bundle_param.copy()\n",
    "    _bundle_param['mode_A'] = _mode_A\n",
    "    path_A = from_bundle_to_A_path(_bundle_param)\n",
    "\n",
    "    if os.path.isfile(path_A):\n",
    "        with open(path_A, 'rb') as f:\n",
    "            A = pkl.load(f)[0]\n",
    "        print(f\"Loading sensing matrix\", _mode_A,\n",
    "                f\"(rsnr: {A['rsnr']:.2f}dB (with bpdn) -- seed: {A['seed']})\")\n",
    "        dict_A[_mode_A] = A['matrix']\n",
    "\n",
    "    else:\n",
    "        warnings.warn(\"Sensing matrix generation. \"\\\n",
    "                        \"Generate with 'best_A_bpdn' for better performances\")\n",
    "        \n",
    "        path_corr = os.path.join(dataset_dir, 'correlation', corr_str + '.pkl')\n",
    "        with open(path_corr, 'rb') as f: corr = pkl.load(f)\n",
    "        \n",
    "        dict_A[_mode_A] = generate_sensing_matrix(\n",
    "                    shape = (m, n), \n",
    "                    mode=_mode_A, \n",
    "                    antipodal=False, \n",
    "                    orthogonal=orth,\n",
    "                    correlation=corr,\n",
    "                    loc=.25, \n",
    "                    seed=seed_A)\n",
    "        print('generated A', _mode_A)\n",
    "        print('A shape:', A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test_loader = {}\n",
    "\n",
    "for _mode_A, _A in dict_A.items():\n",
    "\n",
    "    xall = x_to_dataset(ecg, _A, xbar_index=[1, 2])\n",
    "    \n",
    "    ds = [(xb_, x_) for xb_, x_ in zip(xall['xbarT'], xall['x'])]\n",
    "\n",
    "    train_size = int(0.7 * len(ecg))\n",
    "    val_size = int(0.1 * len(ecg))\n",
    "    test_size = int(0.2 * len(ecg))\n",
    "    train_dataset, val_dataset, test_dataset = random_split(ds, [train_size, val_size, test_size])\n",
    "\n",
    "    # create DataLoaders\n",
    "    batch_size = 64\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    dict_test_loader[_mode_A] = test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:51<00:00, 12.83s/it]\n"
     ]
    }
   ],
   "source": [
    "list_res = []\n",
    "for _model, _p_dict in tqdm(zip(model_list, param_unique_list), total=len(model_list)):\n",
    "    \n",
    "    _t_loader = dict_test_loader[_p_dict['mode_A']]\n",
    "\n",
    "    snr_ = 0.0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in _t_loader:\n",
    "\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = _model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            snr_ += np.mean(compute_rsnr(outputs.detach().cpu().numpy(),\n",
    "                                        targets.detach().cpu().numpy()))\n",
    "            \n",
    "    test_loss /= len(test_loader)\n",
    "    snr_ /= len(test_loader)\n",
    "\n",
    "    _p_dict['SNR'] = snr_\n",
    "    _p_dict['param'] = get_size_model(_model)\n",
    "\n",
    "    list_res += [_p_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: rakeness\t ch: 32\t step: 3\t k: 3\t seed: 0\t SNR: 36.17, (100.0%) param: 714_689 (100.0%)\t index: 1.00\n",
      "A: rakeness\t ch: 32\t step: 3\t k: 3\t seed: 1\t SNR: 36.15, (99.9%) param: 714_689 (100.0%)\t index: 1.00\n",
      "A: rakeness\t ch: 32\t step: 3\t k: 3\t seed: 2\t SNR: 36.13, (99.9%) param: 714_689 (100.0%)\t index: 1.00\n",
      "A: rakeness\t ch: 32\t step: 3\t k: 3\t seed: 3\t SNR: 36.15, (99.9%) param: 714_689 (100.0%)\t index: 1.00\n"
     ]
    }
   ],
   "source": [
    "snr_max = np.max([i['SNR'] for i in list_res])\n",
    "param_max = np.max([i['param'] for i in list_res])\n",
    "for _p_dict in list_res:\n",
    "\n",
    "    print(f\"A: {_p_dict['mode_A']}\\t\",\n",
    "            f\"ch: {_p_dict['expanded_channels']}\\t\",\n",
    "            f\"step: {_p_dict['step_number']}\\t\",\n",
    "            f\"k: {_p_dict['kernel_size']}\\t\",\n",
    "            f\"seed: {_p_dict['seed_torch']}\\t\",\n",
    "            f\"SNR: {_p_dict['SNR']:.2f}, ({_p_dict['SNR']/snr_max *100:.1f}%)\",\n",
    "            f\"param: {_p_dict['param']:_} ({_p_dict['param']/param_max*100:.1f}%)\\t\",\n",
    "            f\"index: {(_p_dict['SNR']/snr_max)/(_p_dict['param']/param_max):.2f}\")\n",
    "    \n",
    "df_res = pd.DataFrame(list_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode_A</th>\n",
       "      <th>expanded_channels</th>\n",
       "      <th>step_number</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>seed_torch</th>\n",
       "      <th>SNR</th>\n",
       "      <th>param</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rakeness</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36.174161</td>\n",
       "      <td>714689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rakeness</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>36.154741</td>\n",
       "      <td>714689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rakeness</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>36.134484</td>\n",
       "      <td>714689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rakeness</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>36.152376</td>\n",
       "      <td>714689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mode_A  expanded_channels  step_number  kernel_size  seed_torch  \\\n",
       "0  rakeness                 32            3            3           0   \n",
       "1  rakeness                 32            3            3           1   \n",
       "2  rakeness                 32            3            3           2   \n",
       "3  rakeness                 32            3            3           3   \n",
       "\n",
       "         SNR   param  \n",
       "0  36.174161  714689  \n",
       "1  36.154741  714689  \n",
       "2  36.134484  714689  \n",
       "3  36.152376  714689  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = df_res.groupby(['mode_A', 'expanded_channels', 'step_number', 'kernel_size'])\n",
    "_df = pd.concat([_df['SNR'].median(), _df['SNR'].std(),_df['param'].median().astype(int),], keys=['SNR median', 'SNR std', 'param'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0ab41_row0_col0, #T_0ab41_row0_col1, #T_0ab41_row0_col2 {\n",
       "  background-color: #ebf3eb;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0ab41\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0ab41_level0_col0\" class=\"col_heading level0 col0\" >SNR median</th>\n",
       "      <th id=\"T_0ab41_level0_col1\" class=\"col_heading level0 col1\" >SNR std</th>\n",
       "      <th id=\"T_0ab41_level0_col2\" class=\"col_heading level0 col2\" >param</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >mode_A</th>\n",
       "      <th class=\"index_name level1\" >expanded_channels</th>\n",
       "      <th class=\"index_name level2\" >step_number</th>\n",
       "      <th class=\"index_name level3\" >kernel_size</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0ab41_level0_row0\" class=\"row_heading level0 row0\" >rakeness</th>\n",
       "      <th id=\"T_0ab41_level1_row0\" class=\"row_heading level1 row0\" >32</th>\n",
       "      <th id=\"T_0ab41_level2_row0\" class=\"row_heading level2 row0\" >3</th>\n",
       "      <th id=\"T_0ab41_level3_row0\" class=\"row_heading level3 row0\" >3</th>\n",
       "      <td id=\"T_0ab41_row0_col0\" class=\"data row0 col0\" >36.153558</td>\n",
       "      <td id=\"T_0ab41_row0_col1\" class=\"data row0 col1\" >0.016233</td>\n",
       "      <td id=\"T_0ab41_row0_col2\" class=\"data row0 col2\" >714689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd4757a62a0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "_df.style.background_gradient(cmap=cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7d082_row0_col0, #T_7d082_row0_col1, #T_7d082_row0_col2 {\n",
       "  background-color: #ebf3eb;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7d082\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7d082_level0_col0\" class=\"col_heading level0 col0\" >SNR median</th>\n",
       "      <th id=\"T_7d082_level0_col1\" class=\"col_heading level0 col1\" >SNR std</th>\n",
       "      <th id=\"T_7d082_level0_col2\" class=\"col_heading level0 col2\" >param</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"index_name level1\" >mode_A</th>\n",
       "      <th id=\"T_7d082_level1_col0\" class=\"col_heading level1 col0\" >rakeness</th>\n",
       "      <th id=\"T_7d082_level1_col1\" class=\"col_heading level1 col1\" >rakeness</th>\n",
       "      <th id=\"T_7d082_level1_col2\" class=\"col_heading level1 col2\" >rakeness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >expanded_channels</th>\n",
       "      <th class=\"index_name level1\" >step_number</th>\n",
       "      <th class=\"index_name level2\" >kernel_size</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7d082_level0_row0\" class=\"row_heading level0 row0\" >32</th>\n",
       "      <th id=\"T_7d082_level1_row0\" class=\"row_heading level1 row0\" >3</th>\n",
       "      <th id=\"T_7d082_level2_row0\" class=\"row_heading level2 row0\" >3</th>\n",
       "      <td id=\"T_7d082_row0_col0\" class=\"data row0 col0\" >36.153558</td>\n",
       "      <td id=\"T_7d082_row0_col1\" class=\"data row0 col1\" >0.016233</td>\n",
       "      <td id=\"T_7d082_row0_col2\" class=\"data row0 col2\" >714689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd4757a5ac0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df.unstack('mode_A').style.background_gradient(cmap=cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Unet Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "nohup_type = 'serial' # None or 'serial' or 'parallel'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_py = os.path.join('experiments', 'Unet_xbar.py')\n",
    "path_py = os.path.join('Unet_xbar.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DATASET PARAMETERS ####\n",
    "\n",
    "size_ecg = 2_000_000\n",
    "# size_ecg = 100_000\n",
    "n = 128\n",
    "seed_ecg = 11\n",
    "\n",
    "#### A PARAMETERS ####\n",
    "\n",
    "modeA = ['rakeness']\n",
    "m = 16\n",
    "str_orth = \"True\"\n",
    "seed_A = 0\n",
    "index_A = 0\n",
    "str_corr = '96af96a7ddfcb2f6059092c250e18f2a'\n",
    "N_try_A = 100\n",
    "\n",
    "#### UNET PARAMETERS ####\n",
    "\n",
    "in_channels = 1\n",
    "seed_torch = [0, 1, 2, 3]\n",
    "expanded_channels = 32\n",
    "step_number = 3\n",
    "kernel_size = 3\n",
    "str_residual = \"True\"\n",
    "str_use_batch_norm = \"False\"\n",
    "str_simple_pool = \"False\"\n",
    "batch_size = 512\n",
    "lr = 0.001\n",
    "\n",
    "#### HARDWARE PARAMETERS ####\n",
    "\n",
    "str_gpus = \"1\"\n",
    "threads = 1\n",
    "workers = 1\n",
    "\n",
    "#### OTHERS ####\n",
    "str_retrain = \"True\"\n",
    "str_resume_train = \"False\"\n",
    "\n",
    "_b = cell_vars(pop='_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'size_ecg': 2000000,\n",
       " 'n': 128,\n",
       " 'seed_ecg': 11,\n",
       " 'modeA': ['rakeness'],\n",
       " 'm': 16,\n",
       " 'str_orth': 'True',\n",
       " 'seed_A': 0,\n",
       " 'index_A': 0,\n",
       " 'str_corr': '96af96a7ddfcb2f6059092c250e18f2a',\n",
       " 'N_try_A': 100,\n",
       " 'in_channels': 1,\n",
       " 'seed_torch': [0, 1, 2, 3],\n",
       " 'expanded_channels': 32,\n",
       " 'step_number': 3,\n",
       " 'kernel_size': 3,\n",
       " 'str_residual': 'True',\n",
       " 'str_use_batch_norm': 'False',\n",
       " 'str_simple_pool': 'False',\n",
       " 'batch_size': 512,\n",
       " 'lr': 0.001,\n",
       " 'str_gpus': '1',\n",
       " 'threads': 1,\n",
       " 'workers': 1,\n",
       " 'str_retrain': 'True',\n",
       " 'str_resume_train': 'False'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict_bundle_cmd = cell_vars(offset=0)\n",
    "dict_bundle_cmd = _b.copy()\n",
    "dict_bundle_cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unravel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of cmd for bash in the same instruction: 4\n"
     ]
    }
   ],
   "source": [
    "dict_bundle_cmd_unravel = unravel_bundle_param(dict_bundle_cmd)[0]\n",
    "print('number of cmd for bash in the same instruction:', len(dict_bundle_cmd_unravel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crate distinct bash commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example: first cmd line:\n",
      "python Unet_xbar.py --size_ecg 2000000 -n 128 --seed_ecg 11 -m 16 --str_orth True --seed_A 0 --index_A 0 --str_corr 96af96a7ddfcb2f6059092c250e18f2a --N_try_A 100 --in_channels 1 --expanded_channels 32 --step_number 3 --kernel_size 3 --str_residual True --str_use_batch_norm False --str_simple_pool False --batch_size 512 --lr 0.001 --str_gpus 1 --threads 1 --workers 1 --str_retrain True --str_resume_train False --modeA rakeness --seed_torch 0\n"
     ]
    }
   ],
   "source": [
    "cmd_bash = []\n",
    "for bundle in dict_bundle_cmd_unravel:\n",
    "    cmd_bash += [from_bundle_to_cmd_bash(path_py, bundle, nohup=False)]\n",
    "\n",
    "print(\"example: first cmd line:\")\n",
    "print(cmd_bash[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File for bash results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res_single_file: nohup_local_gpu=1_date=2024_12_9.log\n",
      "res_global_file: nohup_global_gpu=1_date=2024_12_9.log\n"
     ]
    }
   ],
   "source": [
    "now = time.localtime()\n",
    "now = '_'.join(str(i) for i in [now.tm_year, now.tm_mon, now.tm_mday])\n",
    "res_single_file = f\"nohup_local_gpu={str(str_gpus)}_date={now}.log\"\n",
    "res_global_file = f\"nohup_global_gpu={str(str_gpus)}_date={now}.log\"\n",
    "print(\"res_single_file:\", res_single_file)\n",
    "print(\"res_global_file:\", res_global_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge in one bash command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if nohup_type is not None:\n",
    "    if nohup_type=='parallel':\n",
    "        sep_str = f\"; nohup \"\n",
    "    elif nohup_type=='serial':\n",
    "        sep_str = f\" >{res_single_file} && \"\n",
    "    else:\n",
    "        assert False, \"nohup_type not in [None, 'parallel' or 'serial'] can be used\"\n",
    "else:\n",
    "    sep_str = f\"; \"\n",
    "\n",
    "cmd_bash_final = sep_str.join(cmd_bash)\n",
    "\n",
    "if nohup_type is not None:\n",
    "    if nohup_type=='serial':\n",
    "        cmd_bash_final = f\"nohup sh -c '{cmd_bash_final}'\"\n",
    "\n",
    "if nohup_type:\n",
    "    cmd_bash_final = cmd_bash_final + f\" &> {res_global_file} &\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bash commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nohup sh -c 'python Unet_xbar.py --size_ecg 2000000 -n 128 --seed_ecg 11 -m 16 --str_orth True --seed_A 0 --index_A 0 --str_corr 96af96a7ddfcb2f6059092c250e18f2a --N_try_A 100 --in_channels 1 --expanded_channels 32 --step_number 3 --kernel_size 3 --str_residual True --str_use_batch_norm False --str_simple_pool False --batch_size 512 --lr 0.001 --str_gpus 1 --threads 1 --workers 1 --str_retrain True --str_resume_train False --modeA rakeness --seed_torch 0 >nohup_local_gpu=1_date=2024_12_9.log && python Unet_xbar.py --size_ecg 2000000 -n 128 --seed_ecg 11 -m 16 --str_orth True --seed_A 0 --index_A 0 --str_corr 96af96a7ddfcb2f6059092c250e18f2a --N_try_A 100 --in_channels 1 --expanded_channels 32 --step_number 3 --kernel_size 3 --str_residual True --str_use_batch_norm False --str_simple_pool False --batch_size 512 --lr 0.001 --str_gpus 1 --threads 1 --workers 1 --str_retrain True --str_resume_train False --modeA rakeness --seed_torch 1 >nohup_local_gpu=1_date=2024_12_9.log && python Unet_xbar.py --size_ecg 2000000 -n 128 --seed_ecg 11 -m 16 --str_orth True --seed_A 0 --index_A 0 --str_corr 96af96a7ddfcb2f6059092c250e18f2a --N_try_A 100 --in_channels 1 --expanded_channels 32 --step_number 3 --kernel_size 3 --str_residual True --str_use_batch_norm False --str_simple_pool False --batch_size 512 --lr 0.001 --str_gpus 1 --threads 1 --workers 1 --str_retrain True --str_resume_train False --modeA rakeness --seed_torch 2 >nohup_local_gpu=1_date=2024_12_9.log && python Unet_xbar.py --size_ecg 2000000 -n 128 --seed_ecg 11 -m 16 --str_orth True --seed_A 0 --index_A 0 --str_corr 96af96a7ddfcb2f6059092c250e18f2a --N_try_A 100 --in_channels 1 --expanded_channels 32 --step_number 3 --kernel_size 3 --str_residual True --str_use_batch_norm False --str_simple_pool False --batch_size 512 --lr 0.001 --str_gpus 1 --threads 1 --workers 1 --str_retrain True --str_resume_train False --modeA rakeness --seed_torch 3' &> nohup_global_gpu=1_date=2024_12_9.log &\n"
     ]
    }
   ],
   "source": [
    "print(cmd_bash_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet Parameter exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unet_param': 11521409, 'expanded_channels': 64, 'step_number': 4, 'kernel_size': 3}\n",
      "{'unet_param': 17796609, 'expanded_channels': 64, 'step_number': 4, 'kernel_size': 5}\n",
      "{'unet_param': 24071809, 'expanded_channels': 64, 'step_number': 4, 'kernel_size': 7}\n",
      "{'unet_param': 2860417, 'expanded_channels': 64, 'step_number': 3, 'kernel_size': 3}\n",
      "{'unet_param': 4417025, 'expanded_channels': 64, 'step_number': 3, 'kernel_size': 5}\n",
      "{'unet_param': 5973633, 'expanded_channels': 64, 'step_number': 3, 'kernel_size': 7}\n",
      "{'unet_param': 692609, 'expanded_channels': 64, 'step_number': 2, 'kernel_size': 3}\n",
      "{'unet_param': 1069569, 'expanded_channels': 64, 'step_number': 2, 'kernel_size': 5}\n",
      "{'unet_param': 1446529, 'expanded_channels': 64, 'step_number': 2, 'kernel_size': 7}\n",
      "{'unet_param': 2885313, 'expanded_channels': 32, 'step_number': 4, 'kernel_size': 3}\n",
      "{'unet_param': 4454145, 'expanded_channels': 32, 'step_number': 4, 'kernel_size': 5}\n",
      "{'unet_param': 6022977, 'expanded_channels': 32, 'step_number': 4, 'kernel_size': 7}\n",
      "{'unet_param': 717505, 'expanded_channels': 32, 'step_number': 3, 'kernel_size': 3}\n",
      "{'unet_param': 1106689, 'expanded_channels': 32, 'step_number': 3, 'kernel_size': 5}\n",
      "{'unet_param': 1495873, 'expanded_channels': 32, 'step_number': 3, 'kernel_size': 7}\n",
      "{'unet_param': 174273, 'expanded_channels': 32, 'step_number': 2, 'kernel_size': 3}\n",
      "{'unet_param': 268545, 'expanded_channels': 32, 'step_number': 2, 'kernel_size': 5}\n",
      "{'unet_param': 362817, 'expanded_channels': 32, 'step_number': 2, 'kernel_size': 7}\n",
      "{'unet_param': 723809, 'expanded_channels': 16, 'step_number': 4, 'kernel_size': 3}\n",
      "{'unet_param': 1116033, 'expanded_channels': 16, 'step_number': 4, 'kernel_size': 5}\n",
      "{'unet_param': 1508257, 'expanded_channels': 16, 'step_number': 4, 'kernel_size': 7}\n",
      "{'unet_param': 180577, 'expanded_channels': 16, 'step_number': 3, 'kernel_size': 3}\n",
      "{'unet_param': 277889, 'expanded_channels': 16, 'step_number': 3, 'kernel_size': 5}\n",
      "{'unet_param': 375201, 'expanded_channels': 16, 'step_number': 3, 'kernel_size': 7}\n",
      "{'unet_param': 44129, 'expanded_channels': 16, 'step_number': 2, 'kernel_size': 3}\n",
      "{'unet_param': 67713, 'expanded_channels': 16, 'step_number': 2, 'kernel_size': 5}\n",
      "{'unet_param': 91297, 'expanded_channels': 16, 'step_number': 2, 'kernel_size': 7}\n"
     ]
    }
   ],
   "source": [
    "list_expanded_channels = [64, 32, 16]\n",
    "list_step_number = [4, 3, 2]\n",
    "list_kernel_size = [3, 5, 7]\n",
    "\n",
    "# file_param = 'dummy_Unet_param.pkl'\n",
    "\n",
    "_unet_many_param(list_expanded_channels, list_step_number, \n",
    "                 list_kernel_size, \n",
    "                #  file_param,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameter of the Unet: 11521409\n"
     ]
    }
   ],
   "source": [
    "unet_param = get_size_model(model)\n",
    "print(f'total parameter of the Unet: {unet_param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,)) \n",
      "\n",
      "Param: 12352\n"
     ]
    }
   ],
   "source": [
    "layer_name_list = ['down', 'down_0', 'conv', 'conv_op', '3']\n",
    "sub_model = get_generic_l(model, layer_name_list)\n",
    "print(sub_model, '\\n\\nParam:', get_size_model(sub_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DoubleConv(\n",
      "  (conv_op): Sequential(\n",
      "    (0): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "Param: 12864\n"
     ]
    }
   ],
   "source": [
    "layer_name_list = ['down', 'down_0', 'conv']\n",
    "sub_model = get_generic_l(model, layer_name_list)\n",
    "print(sub_model, '\\n\\nParam:', get_size_model(sub_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (down): DownSeq(\n",
       "    (down_0): DownSample(\n",
       "      (conv): DoubleConv(\n",
       "        (conv_op): Sequential(\n",
       "          (0): Conv1d(1, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (pool): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "    )\n",
       "    (down_1): DownSample(\n",
       "      (conv): DoubleConv(\n",
       "        (conv_op): Sequential(\n",
       "          (0): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (pool): Conv1d(128, 128, kernel_size=(2,), stride=(2,))\n",
       "    )\n",
       "    (down_2): DownSample(\n",
       "      (conv): DoubleConv(\n",
       "        (conv_op): Sequential(\n",
       "          (0): Conv1d(128, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (pool): Conv1d(256, 256, kernel_size=(2,), stride=(2,))\n",
       "    )\n",
       "    (down_3): DownSample(\n",
       "      (conv): DoubleConv(\n",
       "        (conv_op): Sequential(\n",
       "          (0): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (pool): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "    )\n",
       "  )\n",
       "  (bottle_neck): DoubleConv(\n",
       "    (conv_op): Sequential(\n",
       "      (0): Conv1d(512, 1024, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "      (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up): UpSeq(\n",
       "    (up_4): UpSample(\n",
       "      (up): ConvTranspose1d(1024, 512, kernel_size=(2,), stride=(2,))\n",
       "      (conv): DoubleConv(\n",
       "        (conv_op): Sequential(\n",
       "          (0): Conv1d(1024, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up_3): UpSample(\n",
       "      (up): ConvTranspose1d(512, 256, kernel_size=(2,), stride=(2,))\n",
       "      (conv): DoubleConv(\n",
       "        (conv_op): Sequential(\n",
       "          (0): Conv1d(512, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up_2): UpSample(\n",
       "      (up): ConvTranspose1d(256, 128, kernel_size=(2,), stride=(2,))\n",
       "      (conv): DoubleConv(\n",
       "        (conv_op): Sequential(\n",
       "          (0): Conv1d(256, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up_1): UpSample(\n",
       "      (up): ConvTranspose1d(128, 64, kernel_size=(2,), stride=(2,))\n",
       "      (conv): DoubleConv(\n",
       "        (conv_op): Sequential(\n",
       "          (0): Conv1d(128, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Conv1d(64, 1, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_model = UNet(in_channels=in_channels, num_classes=in_channels,\n",
    "                expanded_channels=expanded_channels, steps_num=step_number,\n",
    "                kernel_size=5, residual=residual,\n",
    "                use_batch_norm=use_batch_norm, simple_pool=simple_pool)\n",
    "\n",
    "_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mode_A': 'rakeness', 'use_batch_norm': False, 'seed_torch': 3} -- SNR: 0.66\n"
     ]
    }
   ],
   "source": [
    "\n",
    "_t_loader = dict_test_loader[_p_dict['mode_A']]\n",
    "\n",
    "snr_ = 0.0\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in _t_loader:\n",
    "\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        outputs = _model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        snr_ += np.mean(compute_rsnr(outputs.detach().cpu().numpy(),\n",
    "                                    targets.detach().cpu().numpy()))\n",
    "        \n",
    "test_loss /= len(test_loader)\n",
    "snr_ /= len(test_loader)\n",
    "\n",
    "print(f'{_p_dict} -- SNR: {snr_:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-one",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
